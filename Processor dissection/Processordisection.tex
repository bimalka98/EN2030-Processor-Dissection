\documentclass[a4paper,11pt]{article}
\input{settings/packages}
\input{settings/page}
\input{settings/macros}
\usepackage{url}
\usepackage{subfigure}
\usepackage{wrapfig}

\begin{document}
\input{content/title_page}
\tableofcontents
\section*{\textbf{{Contribution from each member to the project}}}

\begin{table}[!h]
	\centering

		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{Index}	&\textbf{Name} 	&\textbf{Contribution(Sections Covered)}\\ \hline
			&&\\
		180609B  	&SIRITHUNGA M.R.A. &* Micro-Architecture (Data Path and the Controller)\\
		&&* ALU functions\\ \hline&&\\

 		180616T  	&SOMARATHNE P.M.P.H. &* Instruction Set\\
 		&&*  Instruction classes and Instruction Format\\\hline&&\\

 		180631J		&THALAGALA B.P.&* Cache Memory and Memory Interfacing\\
 		&&*  Timing related to Memory\\\hline
		\end{tabular}

			\caption{Contribution from each member to the project}
\end{table}

\pagebreak

 \begin{figure}[!h]
	\centering
	\subfigure[Quad Core Core-i3 8300 Processor]
	{ \includegraphics[scale=0.15, angle= +90]{figures/soc}
			\label{intelsoc}
	}\hspace{1.5cm}
	\subfigure[A Single Core]
	{ \includegraphics[scale=0.41]{figures/core}
			\label{intelcore}
	}
\caption{Intel core-i3 8300 Processor}
\end{figure}

 \begin{figure}[!h]
	\centering
	\subfigure[Dual Core - Cortex -R5 Processor]
	{ \includegraphics[scale=0.25, angle= +90]{figures/r5processor}
			\label{r5processor}
	}\hspace{1.5cm}
	\subfigure[A Single CPU]
	{ \includegraphics[scale=0.45]{figures/r5core}
	\label{r5core}
	}
\caption{ARM Cortex R5 Processor}
\end{figure}
\pagebreak

%============================================================
\section{Instruction Set Architecture of the Processor}

\subsection{Instruction Set}

\subsection{Instruction classes and Instruction Format}
glghuly

%=====================================================================
\vspace{1cm}\hrule

\section{Micro-Architecture (Data Path and the Controller)}
Computer architecture consists of two main branches called instruction set architecture (ISA) and microarchitecture ($\mu$arch). A given ISA can be implemented with different microarchitectures. So, microarchitecture depends on the ISA and the technologies used in implementations. The microarchitecture is the digital logic that defines the way of how the instructions should be executed. Here we have focused on the organization of the Data path and the controller of the internal processor design.
\subsection{Arm Cortex-R5 Processor}
This is a mid-range CPU which is widely used in embedded, real-time systems. To that, ARMv7-R architecture is implemented in cortex-R5.ARM is a RISC architecture. Microcontroller Bus architecture has been embedded with it for better performance. When it comes to the internal design of the processor, the processor may have single or dual CPU configurations. However, the CPU data path is common at all 32bits or 64bits data paths will be used.(Refer figure \ref{r5core}) \\

The PreFetch Unit (PFU) fetches instructions from the memory device, forecasts branches, and forwards instructions to the Data Processing Unit (DPU). Both directions are executed and the Load / Store Unit (LSU) is used for transferring data memory. The L1 interface, which includes L1 instructions and caches and TCM interfaces, is supported with the PFU and LSU interface. The L1 caches are in turn connected to the L2 memory system and the LSU is connected by a more direct peripheral port with the L2 memory system. For cache management needed to be coherent with ACP transactions, the Data Cache interfaces L1 to the $\mu$SCU.\\

\begin{figure}[!h]
	\centering
	\includegraphics[scale= 0.3]{figures/syscc}
	\caption{System control and configuration registers}
\end{figure}

There is a system control coprocessor as the controller in cortex-R5 implementation. All control signals that manipulate the registers, system-level operations, cache maintenance, and such memory system functionalities are produced by this. There are 18 read-only registers and 7 read/write registers among them as shown here.


\subsection{Intel Core i3-8300 Processor}
The internal design of an intel core i3 8300 is very advanced and complicated. It is CISC based microarchitecture called 'Coffee Lake'.  The actual size of a data path is 64 bits. Three levels of caches have been implemented inside it for better performance. Uni-processor configuration is used with four CPU cores and threads in the design. This is pipelined. The focus of the pipelining is to reduce power consumption and enhance overall performance. The coffee lake's pipeline is the same as intel's sky lake pipelining strategies. So, it is embedded in additional parallelism for achieving its performance. The pipeline can be broken down into three zones: the \textbf{\textit{front-end}}, \textit{\textbf{back-end or execution driver}}, and the \textbf{\textit{memory subsystem}}. The front-end aims to feed the back end with an adequate stream of operations that it collects by decoding instructions from memory. The front-end has two primary pathways: the micro-operations($\mu$OPs) cache route and the legacy path. The legacy path is the standard path through which variable-length x86 instructions are extracted from the Level 1 instruction cache, queued, and subsequently decoded into shorter, fixed-length $\mu$OPs. The alternative and much more suitable approach is the $\mu$OPs cache path through which a cache containing already decoded $\mu$OPs receives a hit causing the $\mu$OPs to be transferred directly to the decode list.\\

\begin{wrapfigure}[15]{r}{3.7cm}
	\includegraphics[scale= 0.05]{figures/intuarch}
	\caption{$\mu$arch: of Intel Core-i3 8300}
\end{wrapfigure}
In the back end, a micro-operation visits the reorder buffer. It is where the allocation, renaming, and deletion of the registry takes place. A variety of other optimizations are also performed at this point. The $\mu$OPs are sent from the reorder buffer to the unified scheduler. The scheduler has a variety of escape ports, each of which is attached to a series of separate execution units. Some units can execute simple ALU operations, others can multiply and split, with some units capable of more complex operations, such as separate vector operations. The scheduler is essentially responsible for queuing the $\mu$OPs to the appropriate port so that they can be performed by the appropriate device.Any $\mu$OPs deal with access to memory, load \& store. Those will be sent to the dedicated scheduling ports that can handle the memory operation. Store operations go to the store buffer, which is also capable of forwarding as required. Load operations often come from a load buffer. According to that, the internal design consists of three major sub designs. These are focused on the following improvements, 

 \begin{enumerate}[\hspace{1cm}1.]
 	\item \textbf{	Front end}
 	\begin{enumerate}[I.]
 		\item  	 Increase the legacy pipeline delivery to 5 microoperations.
 		\item Increase the IDQ delivery to 6 microoperations.
 		\item Support 2.28x larger allocation queue that has 64/thread.
 		\item Improves the performance of the branch prediction unit.
 	\end{enumerate}

 	\item\textbf{	Execution engine}
 	\begin{enumerate}[I.]
 		\item  	 Increase the re-order buffer to 224 entries.
 		\item Increase the scheduler to 97 entries and the integer register file to 180 entries.
 		\item Increase the store buffer to 56 entries.
 	\end{enumerate}

 	\item	\textbf{Memory subsystem}
 	\begin{enumerate}[I.]
 		\item 8-way to 4-way set associative mapping.
 	\end{enumerate}
 \end{enumerate}
The fetching and decoding of the instructions are happening separately. Fetched instructions are stored in a queue (FIFO). After decoding, these are executed in the execution engine. All these three subsystems are controlled by the control signals. Generating control signals are done in a control store.
\vspace{1cm}\hrule
\section{ALU functions}

The arithmetic and logic unit is abbreviated as ALU in the computer organization. ALU is responsible for all arithmetic and logical operations. It is implemented by using digital logic for the respective set of operations that are required.

 \begin{figure}[!h]
	\centering
	\subfigure[Core-i3 8300 Processor's ALU]
	{ \includegraphics[scale=0.5]{figures/i3alu}
		\label{i3alu}
	}\hspace{1.5cm}
	\subfigure[Cortex-R5 processors's ALU]
	{ \includegraphics[scale=0.5]{figures/r5alu}
		\label{r5alu}
	}
	\caption{ALUs of the two processors}
\end{figure}

\subsection{Arm Cortex-R5 Processor}
In the eight-stage pipeline, an ALU performs its task. It two data paths that are directly connected with 32 bits registers. Cortex-R5 is well designed for digital signal processing and efficiently performed floating-point number calculations.(figure \ref{r5alu}) Four flags stand for,

\begin{itemize}
	\item 	N - Negative
\item	Z - Zero the ALU output subjected to NOR operation
\item 	C - Carry the Count bit
\item	V - Overflow V bit output
\end{itemize}

\subsection{Intel Core i3-8300 Processor}

Intel's Coffee Lake architecture is used 32bits registers. So, for that ALU should be capable of manipulating these numbers in it. This is implemented by using digital logic.(figure \ref{i3alu}) Two of them are embedded in a processor for,
\begin{itemize}
	\item 	Physical address calculations
	\item	Mathematical operations

\end{itemize}

Core i3 processors are widely used in desktop and laptop general-purpose computers. The clock frequency is around 3.7GHz so, Its ALU is running at a higher speed than its clock rate.




\vspace{1cm}\hrule
\section{Cache Memory and Memory Interfacing}

\subsection{Intel Core i3-8300 Processor}

\subsubsection{Memory Hierarchy}

\paragraph{Cache Memory}
Intel core i3-8300 processor's cache memory is organized using \textbf{\textit{Intel's Smart Cache}} technology. That is the Last Level Cache(LLC) is shared across all cores while the lower level caches are separately allocated for each core such that those  are used by the respective cores privately. The shared cache allows any of the four cores to access the entire storage area of the shared cache(\textit{in this case 8MiB LLC}) and therefore not limited to a dedicated portion of it. This leads to a number of benefits such as, increased resource utilization through providing all of the shared cache to the active cores if the other cores are in the idle mood, reduced front-side bus traffic since shared data can be fetched directly from the LLC(\textit{if available}) into the cores  rather than going all the way to the primary memory\cite{smartcache}.\\

 Following table summarizes the properties of each cache. Refer the \textit{memory subsystem} of the figure \ref{intelcore} to identify the organization of core-private caches while shared cache(LLC/L3\$) is depicted inside the \textit{Ring} of the figure \ref{intelsoc}.\\

{\footnotesize \textit{Consider these abbreviations to refer tables},
D-\textit{Data}, I-\textit{Instruction}, WB-\textit{Write-back}, WT-\textit{Write-through} U-\textit{Unified}, S-\textit{Shared}, SA-\textit{Set Associative}}

 \begin{table}[!h]
	\centering
	\begin{tabular}{l| l |c |c |c|c}
		Cache  & Mapping Technology &Cache Size & No: of Sets&Cache line size& Writing Policy\\
		\hline
		L0 µOP Cache&8-way SA&1,536 µOPs&32&6-µOP&	N/A\\
		L1 I Cache &8-way SA&32 KiB&64&64 B&N/A\\
		L1 D Cache&8-way SA&32 KiB&64&64 B&WB\\
		L2 U cache&4-way SA&256 KiB&1024&64 B&WB\\
		L3 U, S Cache/LLC&Up to 16-way SA&8 MiB&8192&64 B&WB\\
		\hline\hline
	\end{tabular}
	\caption{Cache Memory Organization in Intel core i3-8300 Processors\cite{Coffee}}
\end{table}

\paragraph{Primary/Physical/Main Memory}
The next lower level memory after the L3 cache(LLC) is the System DRAM(Dynamic Random Access Memory) which is also known as the Primary/Main/Physical memory. Intel processors come in 4 different memory channel configurations as, \textit{Single channel, Dual channels, Triple channels and Flex mode}. Intel core i3-8300 Processor is Dual channel and has the capability of reading from or writing to the primary memory in a maximum rate of  37.5GB/s. Moreover the processor supports upto 64GB of DDR4-2400 RAMs(4th generation of Double Data Rate(DDR) RAMs with 2400 Mbps data transfer rate) which is also an ECC(Error-Correcting Code) memory with the ability of detecting and correcting of common types of internal data corruptions.

\subsubsection{Translation-Lookaside Buffers(TLBs)}
In a \textit{\textbf{Virtual Memory System Architecture}}(VMSA)(technique of using primary memory as a cache for the secondary memory) the processor generates \textit{virtual addresses} while the memory is accessed using the \textit{physical addresses}. The mechanism of translating a virtual address to a physical address is called \textbf{\textit{Address Translation/ Mapping}} and it consumes time. Because a single memory access in such a virtual system is actually a two physical memory accesses: first access to obtain the physical address corresponding to the virtual address from the \textit{page table}(part of the memory where physical addresses corresponding to virtual addresses are stored) and the second access to obtain the required data stored in that physical address.\\

To reduce this latency, an address-translation cache which is known as \textbf{\textit{Translation-Lookaside Buffer(TLB)}} where recent address translations are stored is used. In a single core of the Intel core i3-8300 Processor there are three TLBs and their properties are given in the following table while the physical placement is shown in the \textit{Memory Subsystem} and the upper part of the \textit{Front End} of the figure \ref{intelcore}.


\begin{table}[!h]
	\centering
	\begin{tabular}{l |l| c| c| c}
		TLB  & Mapping Technology & Page size & No: of Entries& Partitioning Method\\
		\hline
		I-TLB & 8-way SA & 4 KiB& 128 &Dynamic\\
		D-TLB &  4-way SA & 4 KiB &64 &Fixed\\
		STLB U & 12-way SA&  4 KiB + 2 MiB & 1536 & Fixed\\
		\hline\hline
	\end{tabular}
	\caption{TLBs Organization in Intel core i3-8300 Processors}
\end{table}


\subsubsection{Store Buffers}

Each core of an Intel Core-i3 processor consists of a Store Buffer which is located between the \textit{Port 4}(dedicated port for storing data) of the scheduler and the \textit{L1-Data cache} as shown in the figure \ref{intelcore}. Every \textbf{\textit{memory write}} operation carried out by the processor is temporarily stored in this buffer before they are executed. So the processor does not have to wait until the operation is finished and it can carry out the rest of the instructions freely. This mechanism increases the processor's overall performance through \textit{\textbf{eliminating the unwanted idling}}. 
%11.1 INTERNAL CACHES, TLBS, AND BUFFERS


%==================================================================================

\subsection{Arm Cortex-R5 Processor}

\subsubsection{Memory Hierarchy}

\paragraph{Cache Memory} Arm Cortex-R5 Processor's CPUs only have Level 1(L1) integrated cache controllers while ARM-L2 cache controllers can be connected outside of the processor instance according to the requirement, by the system designer. L1 caches are split as \textit{L1 Instruction cache} and \textit{L1 Data cach}e in order to increase the performance through increasing the bandwidth. Moreover their sizes can be independently configured to be between 4KB and 64KB and each cache can be disabled independently. Data and Instructions are fetched in to the L1 caches via the \textit{AXI master port} at Level 2 Interface(shown in figure \ref{r5core}) from the external memory.\\

 When considering the cache organization of L1 caches, they are always implemented using the \textit{\textbf{Set Associative Mapping Technology}} in order to reduce the cache thrashing(loosing of data in a cache line at a given index, when replacing it with a new cache line with the same index) come across in the Direct Mapping Technology. One cache line consists of \textit{\textbf{8-words}} and \textit{\textbf{Pseudo-random cache replacement policy}}  is used to \textit{randomly select} a cache line to be replaced in a given \textit{set}(a group of cache lines with the same index) for an incoming new cache line at the occurrence of a \textit{cache miss}. Moreover the \textbf{\textit{critical word is first filled}}(the word requested by the processor) to the cache line at such a cache miss, rather than waiting for the whole memory block in order to increase performance. Additionally the writing policy can be configured using the Memory Protection Unit(MPU) to be \textbf{\textit{either write-back or write-through}}.


%\begin{figure}
%	\centering
%	\includegraphics[scale=0.4]{figures/tcm}
%	\caption{}
%	\label{fig:tcm}
%\end{figure}

\begin{wrapfigure}[14]{r}{7cm}
	\includegraphics[scale= 0.315]{figures/tcm}
	\caption{TCMs in Cortex-R5} \label{tcm}
\end{wrapfigure}
\paragraph{Tightly-Coupled Memories (TCMs)}  \textit{Unpredictable access time} at a processor request is a common issue related to the cache memories because, access times at a \textit{cache hit} and a \textit{cache miss} are different in nature. Tightly-Coupled Memories (TCMs) address this issue and provide \textbf{\textit{low-latency}} memory access and \textbf{\textit{consistent access time}} which is ideal for storing time-critical routines\cite{crspg}. Cortex-R5 processor can be configured to have one or two TCMs(ATCM \& BTCM) which are located separately from the processor. They may contain any mix of Data and Instructions and can have capacities upto 8MB. These TCMs can be implemented as SRAMs or ROMs and typically fetch data in a single cycle. ATCM has a single port while BTCM has two ports which can be accessed simultaneously as it is implemented as two banks of RAMs. TCMs can be loaded via the \textit{AXI slave port} at Level 2 Interface(shown in figure \ref{r5core}) and processor can fetch instructions from the TCMs directly without going all the way to an external memory. Although the TCM is implemented as a separate RAM it does not have a dedicated \textit{address space}(set of addresses) and it simply \textbf{\textit{uses a portion of the 32-bit address space}} which is used by the processor at normal operation. Therefore when these TCMs are enabled anything at the same address space(as that is allocated for the TCMs) in the external memory is not accessible to the processor\cite{crtrm}.


\subsubsection{Memory Protection Unit(MPU)}

In a multitasking system, the task currently being executed must not affect the system resources(code, data) of the other tasks. This protection mechanism is controlled by the Operating System(OS), typically with the help of both hardware and software. In ARM Cortex-R series processors which implement the ARM \textit{\textbf{Protected Memory System Architecture}}(PMSA) this feature is provided by a dedicated hardware called \textit{Memory Protection Unit}(MPU)\cite{crspg} located inside the \textit{Level 1 Memory System}(shown in figure \ref{r5core}) of the cores. Using the MPU,  memory can be partitioned into \textbf{\textit{zero, 12 or 16 regions}} and protection attributes can be set for each region independently. The size of such a region is specified by a 5-bit value which encodes a range of values from 32-Bytes(cache-line length) to 4GB.\cite{crtrm}
















% arm cr5 2.3.3 Clocking
% Micro Snoop Control Unit (μSCU)
%---------------------------------------------------------
\vspace{1cm}\hrule
\section{Timing related to Memory}

\subsection{Intel Core i3-8300 Processor}
%18.7 COUNTING CLOCKS
In coffee lake $\mu$architecture the processor is divided into several \textbf{\textit{Clock Domains}} where each part maintains a different clock frequency which is applicable only to that part. All of these frequencies are some multiple of what is known as \textit{Base Clock} which acts only as a reference for other clock domains\cite{Skylake} . Cache memories, their related clock domains, latency and bandwidths are as follows. In addition to that system's DRAMs are operated under the \textit{Memory clock} domain and are capable of transferring data at the rate of 8 bytes per cycle per channel\cite{Coffee}(Core i3-8300 Processor is dual channel as mentioned previously).

 \begin{table}[!h]
	\centering
	\begin{tabular}{l| c|c|c|c }
		Cache &Clock Domain&Fastest Latency&Peak Bandwidth&Sustained Bandwidth\\
		&&(cycles)&(bytes/cyc)&(bytes/cyc)\\\hline
		L1 I Cache&Core Clock &N/A&N/A&N/A\\
		L1 D Cache&Core Clock &4&96&81\\
		L2 U cache&Core Clock &12&64&29\\
		L3 U, S Cache/LLC&Ring Clock&44&32&18\\
		\hline\hline
	\end{tabular}
	\caption{Timing Related to Cache Memory in Intel core i3-8300 Processors\cite{iaorm}}
\end{table}

\subsection{Arm Cortex-R5 Processor} 
%1.4 Interfaces
One Thumb instruction can be fetched on each cycle, whereas each
32-bit ARM instruction requires two clock cycles per fetch.

In many ARM
processor-based systems, access to external memory will take tens or even hundreds of core cycles


CLKIN (Input) Master processor clock.

2.3.3 Clocking

Advanced Microcontroller Bus Architecture (AMBA) AXI and AHB protocols.



\vspace{1cm}\hrule
\section{Comaprison}
\begin{table}[!h]
	\centering
	\begin{tabular}{l ||c| c }
		\textbf{Feature} &\textbf{ARM cortex-R5}&\textbf{Intel Core-i3-8300}\\\hline
		ISA &RISC&CISC\\
		%Micro Architecture &&Coffee Lake($8^{th}$ Gen: Intel)\\
		Memory Sys: Archi:&Protected Mem: Sys: Archi:(PMSA)&Virtual Mem: Sys: Archi:(VMSA)\\
		%Typical clock speed&600 MHz on 40 nm&\\
		\hline\hline
	\end{tabular}
	\caption{}
\end{table}

\subsection{Instruction Set Architecture of the Processor}
\subsection{Micro-Architecture (Data Path and the Controller)}
\subsection{ALU functions}
\subsection{Cache Memory and Memory Interfacing}
\subsection{Timing related to Memory}
\vspace{1cm}\hrule
\bibliographystyle{plain}
\footnotesize
\bibliography{reference}

\end{document}
